{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Binary Classification using Convolutional Neural Networks"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "An investigation into the effects that image augmentation has on the accuracy and loss of Convolutional Neural Networks. *This work was completed as part of dissertation project for Bachelor of Science (Honours) in Computer Science with specialism in Artificial Intelligence.*\n",
    "\n",
    "---"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import Packages\n",
    "Import all the necessary packages for the project to run."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from keras.callbacks import Callback, LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Conv2D\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.layers.core import Activation\n",
    "from keras.layers.core import Flatten\n",
    "from keras.layers.core import Dense\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "import random\n",
    "import classifier_helpers as tools"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Configuration Variables for Experiments"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "results_file_name = 'Batch-Size-2'\n",
    "dataset_path = '../dataset/'\n",
    "rotation_range = 0\n",
    "epochs = 100\n",
    "initial_learning_rate = 1e-5  # 1e-5\n",
    "batch_size = 2\n",
    "decay_rate = initial_learning_rate / epochs  # TODO: Determine the manual decay rate\n",
    "print(\"Decay Rate:\", decay_rate)\n",
    "validation_dataset_size = 0.25\n",
    "random_seed = 42\n",
    "image_depth = 3\n",
    "\n",
    "results_path = 'results/'\n",
    "model_name = results_file_name + \"-\" + str(rotation_range)\n",
    "plot_name = model_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Define Helper Functions"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def get_lr_metric(optimizer):\n",
    "\tdef lr(y_true, y_pred):\n",
    "\t\treturn optimizer.lr\n",
    "\t\n",
    "\treturn lr\n",
    "\n",
    "def stepDecay(epoch):\n",
    "\tdropEvery = 10\n",
    "\tinitAlpha = 0.01\n",
    "\tfactor = 0.25\n",
    "\t# Compute learning rate for current epoch\n",
    "\texp = np.floor((1 + epoch) / dropEvery)\n",
    "\talpha = initAlpha * (factor ** exp)\n",
    "\t\n",
    "\treturn float(alpha)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Build the Network Architecture"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def buildNetworkModel(width, height, depth, classes):\n",
    "\tmodel = Sequential()\n",
    "\tinput_shape = (height, width, depth)\n",
    "\t\n",
    "\t# If 'channel first' is being used, update the input shape\n",
    "\tif K.image_data_format() == 'channel_first':\n",
    "\t\tinput_shape = (depth, height, width)\n",
    "\t\n",
    "\t# First layer\n",
    "\tmodel.add(\n",
    "\t\tConv2D(20, (5, 5), padding = \"same\", input_shape = input_shape))  # Learning 20 (5 x 5) convolution filters\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "\t\n",
    "\t# Second layer\n",
    "\tmodel.add(Conv2D(50, (5, 5), padding = \"same\"))\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\tmodel.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "\t\n",
    "\t# Third layer - fully-connected layers\n",
    "\tmodel.add(Flatten())\n",
    "\tmodel.add(Dense(50))  # 500 nodes\n",
    "\tmodel.add(Activation(\"relu\"))\n",
    "\t\n",
    "\t# Softmax classifier\n",
    "\tmodel.add(Dense(classes))  # number of nodes = number of classes\n",
    "\tmodel.add(Activation(\"softmax\"))  # yields probability for each class\n",
    "\t\n",
    "\t# Return the model\n",
    "\treturn model\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Load and Initialise the Dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sorted_data = np.load('sorted_data_array.npy')\n",
    "sorted_labels = np.load('sorted_labels_array.npy')\n",
    "data = []\n",
    "labels = []\n",
    "\n",
    "combined = list(zip(sorted_data, sorted_labels))\n",
    "random.shuffle(combined)\n",
    "data[:], labels[:] = zip(*combined)\n",
    "\n",
    "# Scale the raw pixel intensities to the range [0, 1]\n",
    "data = np.array(data, dtype = \"float\") / 255.0\n",
    "labels = np.array(labels)\n",
    "\n",
    "test_set = int(validation_dataset_size * len(labels))\n",
    "validation_dataset_labels = labels[-test_set:]\n",
    "\n",
    "# Partition the data into training and testing splits\n",
    "(train_x, test_x, train_y, test_y) = train_test_split(data, labels, test_size = test_set, random_state = random_seed)\n",
    "\n",
    "# Convert the labels from integers to vectors\n",
    "train_y = to_categorical(train_y, num_classes = 2)\n",
    "test_y = to_categorical(test_y, num_classes = 2)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Define Image Augmentation Generators"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "training_augmented_image_generator = ImageDataGenerator(rotation_range = rotation_range, fill_mode = \"nearest\")\n",
    "testing_augmented_image_generator = ImageDataGenerator(rotation_range = rotation_range, fill_mode = \"nearest\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Compile the Network Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(tools.stamp() + \"Compiling Network Model\")\n",
    "\n",
    "# Reducing the learning rate by half every 2 epochs\n",
    "learning_rate_schedule = [LearningRateScheduler(stepDecay)]\n",
    "\n",
    "# Build the model based on control variable parameters\n",
    "model = buildNetworkModel(width = 64, height = 64, depth = image_depth, classes = 2)\n",
    "\n",
    "# Set optimiser\n",
    "optimiser = Adam(lr = initial_learning_rate)\n",
    "lr_metric = get_lr_metric(optimiser)\n",
    "\n",
    "# Compile the model using binary crossentropy, preset optimiser and selected metrics\n",
    "model.compile(loss = \"binary_crossentropy\", optimizer = optimiser, metrics = [\"accuracy\", \"mean_squared_error\", lr_metric])\n",
    "# Train the network\n",
    "print(tools.stamp() + \"Training Network Model\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "## Save the Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Save results of training in history dictionary for statistical analysis\n",
    "history = model.fit_generator(\n",
    "\ttraining_augmented_image_generator.flow(train_x, train_y, batch_size = batch_size),\n",
    "\tvalidation_data = (test_x, test_y),\n",
    "\tsteps_per_epoch = len(train_x) // batch_size,\n",
    "\tepochs = epochs,\n",
    "\tverbose = 1)\n",
    "\n",
    "# Save all runtime statistics and plot graphs\n",
    "tools.saveNetworkStats(history, epochs, initial_learning_rate, model_name, results_path)\n",
    "tools.saveAccuracyGraph(history, plot_name, results_path)\n",
    "tools.saveLossGraph(history, plot_name, results_path)\n",
    "tools.saveLearningRateGraph(history, plot_name, results_path)\n",
    "tools.saveModelToDisk(model, model_name, results_path)\n",
    "tools.saveWeightsToDisk(model, model_name, results_path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}